{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import os\n",
    "import shapefile # this is installed as \"PyShp\" library\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import netCDF4 as nc4\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.read_files import make_default_path, read_from_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the name of the 'active' file in a variable\n",
    "controlFile = 'control_TuolumneRiver.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the path where the merged forcing is\n",
    "mergePath = read_from_control(controlFile,'forcing_merged_path')\n",
    "# Specify the default path if required\n",
    "if mergePath == 'default':\n",
    "    mergePath = make_default_path('forcing/2a_merged_data', controlFile)\n",
    "else: \n",
    "    mergePath = Path(mergePath) # ensure Path() object  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find file path\n",
    "geoPath = read_from_control(controlFile,'forcing_geo_path')\n",
    "geoName = 'gridmet_dem.nc'\n",
    "# Specify the default path if required\n",
    "if geoPath == 'default':\n",
    "    geoPath = make_default_path('forcing/0_geopotential', controlFile)\n",
    "else: \n",
    "    geoPath = Path(geoPath) # ensure Path() object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the path where the new shapefile needs to go\n",
    "shapePath = read_from_control(controlFile,'forcing_shape_path')\n",
    "\n",
    "# Specify the default path if required\n",
    "if shapePath == 'default':\n",
    "    shapePath = make_default_path('shapefiles/forcing', controlFile)\n",
    "else: \n",
    "    shapePath = Path(shapePath) # ensure Path() object \n",
    "    \n",
    "# Find name of the new shapefile\n",
    "shapeName = read_from_control(controlFile,'forcing_shape_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the names of the latitude and longitude fields\n",
    "field_lat = read_from_control(controlFile,'forcing_shape_lat_name')\n",
    "field_lon = read_from_control(controlFile,'forcing_shape_lon_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Read the source file to find the grid spacing\n",
    "# Find an .nc file in the forcing path\n",
    "for file in os.listdir(mergePath):\n",
    "    if file.endswith('.nc'):\n",
    "        forcing_file = file\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dimension variable names\n",
    "source_name_lat = \"y\"\n",
    "source_name_lon = \"x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file and get the dimensions  and thus the spatial extent of the domain\n",
    "with nc4.Dataset(mergePath / forcing_file) as src:\n",
    "    lat = src.variables[source_name_lat][:]\n",
    "    lon = src.variables[source_name_lon][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the spacing\n",
    "half_dlat = abs(lat[1] - lat[0])/2\n",
    "half_dlon = abs(lon[1] - lon[0])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create the new shape\n",
    "with shapefile.Writer(str(shapePath / shapeName)) as w:\n",
    "    w.autoBalance = 1 # turn on function that keeps file stable if number of shapes and records don't line up\n",
    "    w.field(\"ID\",'N') # create (N)umerical attribute fields, integer\n",
    "    w.field(field_lat,'F',decimal=4) # float with 4 decimals\n",
    "    w.field(field_lon,'F',decimal=4)\n",
    "    ID = 0 # start ID counter of empty\n",
    "    \n",
    "    for i in range(0,len(lon)):\n",
    "        for j in range(0,len(lat)):\n",
    "            ID += 1\n",
    "            center_lon = lon[i]\n",
    "            center_lat = lat[j]\n",
    "            vertices = []\n",
    "            parts = []\n",
    "            vertices.append([center_lon-half_dlon, center_lat])\n",
    "            vertices.append([center_lon-half_dlon, center_lat+half_dlat])\n",
    "            vertices.append([center_lon          , center_lat+half_dlat])\n",
    "            vertices.append([center_lon+half_dlon, center_lat+half_dlat])\n",
    "            vertices.append([center_lon+half_dlon, center_lat])\n",
    "            vertices.append([center_lon+half_dlon, center_lat-half_dlat])\n",
    "            vertices.append([center_lon          , center_lat-half_dlat])\n",
    "            vertices.append([center_lon-half_dlon, center_lat-half_dlat])\n",
    "            vertices.append([center_lon-half_dlon, center_lat])\n",
    "            parts.append(vertices)\n",
    "            w.poly(parts)\n",
    "            w.record(ID, center_lat, center_lon)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Add the geopotential data to the shape\n",
    "# Open the geopotential data file\n",
    "geo = xr.open_dataset( geoPath / geoName )\n",
    "\n",
    "# Open shapefile\n",
    "shp = gpd.read_file( shapePath / shapeName )\n",
    "\n",
    "# write crs to shp\n",
    "shp = shp.set_crs(\"EPSG:4326\")\n",
    "\n",
    "# Add new column to shapefile\n",
    "shp = shp.assign(elev_m = -999)  # insert a placeholder value\n",
    "\n",
    "# For each row in the shapefile, match its ERA5 lat/lon coordinates \n",
    "# with those in the 'geo' file and extract the appropriate geopotential\n",
    "for index, row in shp.iterrows():\n",
    "       \n",
    "    # Find elevation\n",
    "    elev = geo['elevation'].sel(y = row['y'], x=row['x'], method='nearest').values.flatten()\n",
    "    \n",
    "    # Add elevation into shapefile\n",
    "    shp.at[index,'elev_m'] = int(elev[0])\n",
    "    \n",
    "# Overwrite the existing shapefile\n",
    "shp.to_file( shapePath / shapeName )\n",
    "\n",
    "# close the files\n",
    "geo.close()\n",
    "shp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
