{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stageiv_data(date, region='conus'):\n",
    "    \"\"\"\n",
    "    Download Stage IV precipitation data for a given date and region.\n",
    "    \"\"\"\n",
    "    base_url = \"https://water.noaa.gov/resources/downloads/precip/stageIV/\"\n",
    "    date_str = date.strftime(\"%Y/%m/%d\")\n",
    "    file_name = f\"nws_precip_1day_{date.strftime('%Y%m%d')}_{region}.nc\"\n",
    "    url = f\"{base_url}{date_str}/{file_name}\"\n",
    "    \n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".nc\")\n",
    "    temp_path = temp_file.name\n",
    "    temp_file.close()\n",
    "    \n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(temp_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        return temp_path\n",
    "    \n",
    "    os.unlink(temp_path)  # Delete if download fails\n",
    "    return None\n",
    "\n",
    "def clip_to_shapefile(nc_file, shapefile):\n",
    "    \"\"\"\n",
    "    Clip the downloaded NetCDF file using a given shapefile.\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(shapefile)\n",
    "    if nc_file is None:\n",
    "        return None\n",
    "    \n",
    "    ds = xr.open_dataset(nc_file)\n",
    "    # add crs\n",
    "    ds = ds.rio.write_crs(\"+proj=stere +lat_0=90 +lat_ts=60 +lon_0=-105 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs\")\n",
    "    ds = ds.rio.reproject(gdf.crs)\n",
    "    ds = ds.rio.clip_box(minx=gdf.geometry.total_bounds[0],\n",
    "                          miny=gdf.geometry.total_bounds[1],\n",
    "                          maxx=gdf.geometry.total_bounds[2],\n",
    "                          maxy=gdf.geometry.total_bounds[3], crs=gdf.crs)\n",
    "    return ds\n",
    "\n",
    "def build_annual_dataset(water_year, shapefile, region='conus', test=False):\n",
    "    \"\"\"\n",
    "    Download and process daily Stage IV precipitation data for an entire water year (Oct 1 - Sep 30).\n",
    "    \"\"\"\n",
    "    start_date = datetime(water_year - 1, 10, 1)  # Water year starts on Oct 1 of previous year\n",
    "    end_date = datetime(water_year, 9, 30)  # Ends on Sep 30 of current year\n",
    "    \n",
    "    if test:\n",
    "        start_date = datetime(water_year, 1, 1)\n",
    "        end_date = datetime(water_year, 1, 5)\n",
    "\n",
    "    datasets = []\n",
    "    date = start_date\n",
    "    while date <= end_date:\n",
    "        try:\n",
    "            nc_file = download_stageiv_data(date, region)\n",
    "            clipped_ds = clip_to_shapefile(nc_file, shapefile)\n",
    "            gdf = gpd.read_file(shapefile)\n",
    "            if clipped_ds is None:\n",
    "                # Create a NaN-filled dataset with the expected shape\n",
    "                dummy_ds = xr.full_like(xr.open_dataset(nc_file) if nc_file else None, np.nan)\n",
    "                # add crs\n",
    "                dummy_ds = dummy_ds.rio.write_crs(\"+proj=stere +lat_0=90 +lat_ts=60 +lon_0=-105 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs\")\n",
    "                clipped_ds = dummy_ds.rio.clip(minx=gdf.geometry.total_bounds[0],\n",
    "                          miny=gdf.geometry.total_bounds[1],\n",
    "                          maxx=gdf.geometry.total_bounds[2],\n",
    "                          maxy=gdf.geometry.total_bounds[3], crs=gdf.crs)\n",
    "            \n",
    "            datasets.append(clipped_ds)\n",
    "            \n",
    "            # Clear temporary file from disk\n",
    "            if nc_file:\n",
    "                os.unlink(nc_file)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {date.strftime('%Y-%m-%d')}: {e}\")\n",
    "        \n",
    "        date += timedelta(days=1)\n",
    "    \n",
    "        # concatetate the datasets\n",
    "        ds = xr.concat(datasets, dim='time')\n",
    "        # convert to crs of shapefile\n",
    "        ds = ds.rio.reproject(gdf.crs)\n",
    "        # convert from inches to mm for observation, normal, and departure from normal\n",
    "        ds['observation'] = ds['observation'] * 25.4\n",
    "        ds['normal'] = ds['normal'] * 25.4\n",
    "        ds['departure_from_normal'] = ds['departure_from_normal'] * 25.4\n",
    "        # change the attribte units to mm\n",
    "        ds['observation'].attrs['units'] = 'mm'\n",
    "        ds['normal'].attrs['units'] = 'mm'\n",
    "        ds['departure_from_normal'].attrs['units'] = 'mm'\n",
    "        \n",
    "    return ds\n",
    "\n",
    "def test_build_annual_dataset():\n",
    "    \"\"\"\n",
    "    Test function to check if build_annual_dataset works correctly on a small subset of data.\n",
    "    \"\"\"\n",
    "    water_year = 2023\n",
    "    shapefile = \"/storage/dlhogan/summa_modeling_data/domain_EastRiver/shapefiles/catchment/EastRiver.shp\" \n",
    "    test_ds = build_annual_dataset(water_year, shapefile, test=True)\n",
    "    \n",
    "    assert isinstance(test_ds, xr.Dataset), \"Output is not an xarray Dataset\"\n",
    "    assert 'time' in test_ds.dims, \"Time dimension missing in output dataset\"\n",
    "    print(\"Test passed: build_annual_dataset produces valid output.\")\n",
    "    return test_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: build_annual_dataset produces valid output.\n"
     ]
    }
   ],
   "source": [
    "test_ds = test_build_annual_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage IV data for water year 2022 already exists.\n",
      "Saved stage IV data for water year 2023\n"
     ]
    }
   ],
   "source": [
    "wys = [2022,2023]\n",
    "for wy in wys:\n",
    "    basin='TuolumneRiver'\n",
    "    shapefile = f\"/storage/dlhogan/summa_modeling_data/domain_{basin}/shapefiles/catchment/{basin}.shp\"\n",
    "    if os.path.exists(f\"/storage/dlhogan/summa_modeling_data/domain_{basin}/forcing/1_raw_data/stageIV/stageiv_{wy}_{basin}.nc\"):\n",
    "        print(f\"Stage IV data for water year {wy} already exists.\")\n",
    "        continue\n",
    "    else:\n",
    "        ds = build_annual_dataset(wy, shapefile)\n",
    "        ds.to_netcdf(f\"/storage/dlhogan/summa_modeling_data/domain_{basin}/forcing/1_raw_data/stageIV/stageiv_{wy}_{basin}.nc\")\n",
    "        print(f\"Saved stage IV data for water year {wy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f\"/storage/dlhogan/summa_modeling_data/domain_{basin}/forcing/1_raw_data/stageIV/stageiv_{basin}_{wys[0]}_{wys[1]}.nc\"):\n",
    "    print(f\"Merged Stage IV data already exists.\")\n",
    "else:\n",
    "    # merge the datasets\n",
    "    ds = xr.open_mfdataset(f\"/storage/dlhogan/summa_modeling_data/domain_{basin}/forcing/1_raw_data/stageIV/*.nc\")\n",
    "\n",
    "    # save the merged dataset\n",
    "    ds.to_netcdf(f\"/storage/dlhogan/summa_modeling_data/domain_{basin}/forcing/1_raw_data/stageIV/stageiv_{basin}_{wys[0]}_{wys[1]}.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
